{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UTFSM](https://github.com/tclaudioe/Scientific-Computing-V3/blob/main/images/Departamento%20de%20Inform%C3%A1tica%20cromatica%20negra%404x-8.png?raw=true)\n",
    "# INF-285 - Computación Científica\n",
    "## Least Squares\n",
    "## Version: 1.41\n",
    "## [Acknowledgements](#acknowledgements)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tclaudioe/Scientific-Computing-V3/blob/main/06_Least_Squares.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='toc' />\n",
    "\n",
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* [Overdetermined Linear System of Equations](#over)\n",
    "    * [Initial Example](#initialExample)\n",
    "* [QR Factorization](#qr)\n",
    "    * [Do we really have _truly_ unitary vectors?](#DoWeReallyHaveUnitaryVectors)\n",
    "    * [Examples of QR: Classic vs Modified Gram-Schmidt](#ex)\n",
    "    * [Using the QR factorization to solve least-square problems](#qrls)\n",
    "* [Addional examples](#sm)\n",
    "* [Acknowledgements](#acknowledgements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy is already installed.\n",
      "scipy is already installed.\n",
      "matplotlib is already installed.\n",
      "colorama is already installed.\n",
      "bitstring is already installed.\n",
      "sympy is already installed.\n",
      "ipywidgets is already installed.\n",
      "pandas is already installed.\n",
      "Running on local environment\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# CoLab requirements\n",
    "# https://stackoverflow.com/questions/44210656/how-to-check-if-a-module-is-installed-in-python-and-if-not-install-it-within-t\n",
    "##########################\n",
    "\n",
    "# https://pypi.org/project/colorama/\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "    \n",
    "# install_colab_requirements \n",
    "libraries = ['numpy', 'scipy', 'matplotlib', 'colorama', \n",
    "            'bitstring', 'sympy', 'ipywidgets','pandas']\n",
    "\n",
    "for library in libraries:\n",
    "    # Check if the library is already installed\n",
    "    if importlib.util.find_spec(library) is not None:\n",
    "        print(f\"{library} is already installed.\")\n",
    "    else:\n",
    "        print(f\"{library} is not installed. Installing...\")\n",
    "        # Install the library using pip\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", library])\n",
    "        print(f\"{library} has been installed.\")\n",
    "# https://stackoverflow.com/questions/53581278/test-if-notebook-is-running-on-google-colab\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    print('Installing LaTeX support in CoLab')\n",
    "    # Adding LaTeX dependencies to CoLab: https://stackoverflow.com/questions/55746749/latex-equations-do-not-render-in-google-colaboratory-when-using-matplotlib\n",
    "    !sudo apt install cm-super dvipng texlive-latex-extra texlive-latex-recommended\n",
    "else:\n",
    "   print('Running on local environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import scipy.linalg as spla # type: ignore\n",
    "%matplotlib inline\n",
    "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
    "from sklearn import datasets # type: ignore\n",
    "import ipywidgets as widgets # type: ignore\n",
    "import matplotlib as mpl # type: ignore\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 20\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "M=8\n",
    "from ipywidgets import interact # type: ignore\n",
    "# https://pypi.org/project/colorama/\n",
    "# %conda install -c anaconda colorama\n",
    "# or\n",
    "# !pip install colorama\n",
    "from colorama import Fore, Back, Style # type: ignore\n",
    "# https://pypi.org/project/colorama/\n",
    "# Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n",
    "# Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.\n",
    "# Style: DIM, NORMAL, BRIGHT, RESET_ALL\n",
    "textBold = lambda x: Style.BRIGHT+x+Style.RESET_ALL\n",
    "textBoldH = lambda x: Style.BRIGHT+Back.YELLOW+x+Style.RESET_ALL\n",
    "\n",
    "textQRClassic = lambda x: Style.BRIGHT+Fore.RED+x+Style.RESET_ALL\n",
    "textQRModified = lambda x: Style.BRIGHT+Fore.BLUE+x+Style.RESET_ALL\n",
    "textAnswer = lambda x: Style.BRIGHT+Back.YELLOW+Fore.WHITE+x+Style.RESET_ALL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro' />\n",
    "\n",
    "## Introduction\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "We have learned about **square** linear system of equations. \n",
    "However, can we solve a **non-square/rectangular** linear system of equations? i.e. when we have more equations than unknowns!\n",
    "Well, a traditional alternative is to find a least squares approximation!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='over' />\n",
    "\n",
    "# Overdetermined Linear Systems of Equations\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "There are cases where the number of equations is greater than the number of unknowns. \n",
    "Many times, these systems don't have an exact solution (they are inconsistent system).\n",
    "In this case, we find a numerical approximation that minimizes an error.\n",
    "In particular, we use as error the vector 2-norm for the residual vector.\n",
    "We define the **minimal** residual vector as:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathbf{r} &= \\mathbf{b}-A\\,\\overline{\\mathbf{x}}.\n",
    "\\end{align*}\n",
    "$$\n",
    "We know the following for this **minimal** residual vector:\n",
    "1. $\\mathbf{b}$ corresponds to the vector that **we want** to represent as a **linear combination of the column vectors of the matrix $A$**, i.e. $A\\,\\mathbf{x}$.\n",
    "2. Among all the vectors that belong to the column-space of $A$, i.e. $A\\,\\mathbf{x}$, there is only one vector that minimizes the **distance** between the vector $\\mathbf{b}$ and the vectors that belong to the column-space of $A$. This minimizer is denoted as $A\\,\\overline{\\mathbf{x}}$.\n",
    "3. The minimal distance can be computed as the 2-norm of the difference between $\\mathbf{b}$ and $A\\,\\overline{\\mathbf{x}}$. This means that the 2-norm of the residual vector $\\mathbf{r} = \\mathbf{b}-A\\,\\overline{\\mathbf{x}}$, which is $\\|\\mathbf{r}\\|$ is the minimal distance.\n",
    "4. Another important condition we can highlight is the **ortogonality** between the residual vector $\\mathbf{r}$ and the column-space of $A$, i.e. all the vectors that can be represented as $A\\,\\mathbf{x}$. \n",
    "This induces the following equation $\\langle A\\,\\mathbf{x}, \\mathbf{r} \\rangle=0$, i.e. the inner product is equal to 0.\n",
    "Replacing the definition of $\\mathbf{r}$, we obtain,\n",
    "\\begin{align*} \n",
    "    \\left(A\\,\\mathbf{x}\\right)^\\top\\,\\left(\\mathbf{b}-A\\,\\overline{\\mathbf{x}}\\right)&=0,   && \\textrm{Expanding the Transpose operator $^\\top$},\\\\\n",
    "    \\mathbf{x}^\\top\\, A^\\top\\,\\left(\\mathbf{b}-A\\,\\overline{\\mathbf{x}}\\right)&=0,          && \\textrm{Re-organizing the terms},\\\\\n",
    "    \\underbrace{\\mathbf{x}^\\top}_{\\displaystyle\\textrm{(I)}}\\, \\underbrace{\\left(A^\\top\\,\\mathbf{b}-A^\\top\\,A\\,\\overline{\\mathbf{x}}\\right)}_{\\displaystyle\\textrm{(II)}}&=0,\n",
    "\\end{align*}\n",
    "Now, recalling that the residual must be orthogonal to any vector that belong to the column-space of $A$, this implies that the vector $\\mathbf{x}$, i.e. $\\textrm{(I)}$ can't assure the product will be $0$. Therefore, the term  $\\textrm{(II)}$ must be the null-vector.\n",
    "Thus,\n",
    "\\begin{align*} \n",
    "    A^\\top\\,\\mathbf{b}-A^\\top\\,A\\,\\overline{\\mathbf{x}}&=\\mathbf{0}, \\\\\n",
    "    A^\\top\\,A\\,\\overline{\\mathbf{x}}&= A^\\top\\,\\mathbf{b}. \\\\\n",
    "\\end{align*}\n",
    "\n",
    "This last equation gives us a new **square** $n\\times n$ matrix, which can be solved with any linear system of equations solver.\n",
    "This linear system of equations is known as the **Normal Equations**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='initialExample' />\n",
    "\n",
    "## Initial example:\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "In this example we will approximate $m$ points considering a linear relationship between the variables $x$ and $y$.\n",
    "Consider that we have $m$ data points  $(x_i,y_i)$ for $i\\in\\{1,2,\\dots,m\\}$, and we consider the relationshop $y=a_0+a_1\\,x$.\n",
    "\n",
    "**Notice: \n",
    "The linear approximation here proposed is the typical example one could use, but you could also use other kind of approximations, for instance $y=a_0+a_1\\,x+a_2\\,x^2$, and so on. \n",
    "It is important to highlight that even though the relation between the _dependent_ variable $y$ and the _independent_ is not linear in this last example, the problem we will be solving with least-square will still be ``linear'' on the unknowns variables $a_0$, $a_1$, and $a_2$, respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of points to be used\n",
    "m = 100\n",
    "# Relationship considered\n",
    "fv = np.vectorize(lambda x, a0, a1: a0+a1*x)\n",
    "# \"Exact\" coefficients considered\n",
    "a0_exact, a1_exact = 1, 4\n",
    "\n",
    "# Fixing the 'seed' of the random number generator to obtain reproducible outcomes.\n",
    "rng = np.random.Generator(np.random.PCG64(seed=0))\n",
    "\n",
    "# Error:\n",
    "# Standard deviation for the error\n",
    "sigma = 5e-1\n",
    "# Error to be added\n",
    "e = rng.normal(0, sigma, m)\n",
    "\n",
    "# Generating data points\n",
    "x = np.linspace(0,1,m)\n",
    "y = fv(x,a0_exact,a1_exact)+e\n",
    "# Challenging question: What if all the xi are the same?\n",
    "# This means that considering the following definition for x, for instance:\n",
    "# x = np.linspace(0,1,m)*0+0.5\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(x,y,'b.',markersize=20, label='Data points')\n",
    "plt.plot(x,fv(x,a0_exact,a1_exact),'k-',linewidth=8,alpha=0.8, label='Original function')\n",
    "plt.legend(loc='lower left', ncol=1, fancybox=True, shadow=True, numpoints=1, bbox_to_anchor=(1,0))\n",
    "plt.grid(True)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot before was build from a _arbitrary_ defined values for $a_0=1$ and $a_1=4$, to then later add some errors $\\varepsilon_i$ that follow a Normal distribution $\\mathrm{N}(0,\\sigma)$, for $\\sigma=5\\,10^{-1}$.\n",
    "This way we generated the <span style=\"color:blue\">blue</span> **data points**.\n",
    "_The purpose of this numerical experiment is to try to recover the **exact** values for $a_0$ and $a_1$ from the **data points** that have error of the $y$ component_.\n",
    "\n",
    "Now, we will solve the _least-square_ problem with the **Normal Equations**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the data matrix\n",
    "A = np.ones((m,2))\n",
    "A[:,1] = x\n",
    "# Setting up the right hand side\n",
    "b = y\n",
    "\n",
    "# Building and solving the normal equations\n",
    "# A^T A x_bar = A^T b\n",
    "x_bar = np.linalg.solve(A.T @ A, A.T @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare the solution found with the exact solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0_exact\t: 1\n",
      "a0_bar  \t: 1.0041518440034327 \n",
      "\n",
      "a1_exact\t: 4\n",
      "a1_bar  \t: 4.072793005483851\n"
     ]
    }
   ],
   "source": [
    "print('a0_exact\\t:',a0_exact)\n",
    "print('a0_bar  \\t:',x_bar[0],'\\n')\n",
    "\n",
    "print('a1_exact\\t:',a1_exact)\n",
    "print('a1_bar  \\t:',x_bar[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Are the least-square approximation close to the **exact** values?\n",
    "- Do they have to be close?\n",
    "- How does the error changes as we increase $m$ (the number of data points)?\n",
    "- How does the error changes as we change standard deviation of the error added? Recall that we added an error to perturbate the data points, actually we only perturbated the $y$ values, not the $x$ values.\n",
    "\n",
    "To answer these questions, keep reading the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic error of LS solution:  23.097326701044185\n",
      "\u001b[1m\u001b[43m\u001b[37mThis is the actual minimum of the least-square error since this is what does the solution of the Normal Equations.\n",
      "\u001b[0m\n",
      "Quadratic error of original parameters:  23.306792448000188\n",
      "\u001b[1m\u001b[43m\u001b[37mOn the other hand, it may look counterintuitive that the ORIGINAL, i.e. exact, solution get a higher value for the error.\u001b[0m\n",
      "\u001b[1m\u001b[43m\u001b[37mThis is actually correct since the solution that minimizes the LS error is the solution to the Normal Equations and not the EXACT solution.\n",
      "\u001b[0m\n",
      "Inner product of rLS and each column of A:  [-2.08721929e-14 -8.10462808e-15]\n",
      "\u001b[1m\u001b[43m\u001b[37mThe previous output shows that the residual vector r=b-A @ x_bar is actually orthogonal to the column space of A, i.e. the range of A.\n",
      "\u001b[0m\n",
      "Inner product of rOR and each column of A:  [4.05483467 2.64628043]\n",
      "\u001b[1m\u001b[43m\u001b[37mOn the other hand, the residual vector with the exact solution is NOT orthogonal, which is OK since this is not required.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Computing the quadratic error ||r||_2^2 of the least-square solution\n",
    "print('Quadratic error of LS solution: ',np.power(np.linalg.norm(b-A @ x_bar),2))\n",
    "print(textAnswer('This is the actual minimum of the least-square error since this is what does the solution of the Normal Equations.\\n'))\n",
    "\n",
    "# Computing the quadratic error ||r||_2^2 of the \"original\" parameters\n",
    "x_original = np.array([a0_exact,a1_exact])\n",
    "print('Quadratic error of original parameters: ',np.power(np.linalg.norm(b-A @ x_original),2))\n",
    "print(textAnswer('On the other hand, it may look counterintuitive that the ORIGINAL, i.e. exact, solution get a higher value for the error.'))\n",
    "print(textAnswer('This is actually correct since the solution that minimizes the LS error is the solution to the Normal Equations and not the EXACT solution.\\n'))\n",
    "\n",
    "# Verifying if the columns of A are orthogonal to the \"residual\" vector rLS=b-A*x_bar.\n",
    "print('Inner product of rLS and each column of A: ',A.T @ (b-A @ x_bar))\n",
    "print(textAnswer('The previous output shows that the residual vector r=b-A @ x_bar is actually orthogonal to the column space of A, i.e. the range of A.\\n'))\n",
    "\n",
    "# Computing the ortogonality condition against the \"original\" a0_exact y a1_exact, i.e. rOR=b-A*x_no_bar\n",
    "print('Inner product of rOR and each column of A: ',A.T @ (b-A @ x_original))\n",
    "print(textAnswer('On the other hand, the residual vector with the exact solution is NOT orthogonal, which is OK since this is not required.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just execute the following cell and play with the widget below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a0        : Input approximation from widget for a_0 in a_0+a_1*x\n",
    "# a1        : Input approximation from widget for a_0 in a_0+a_1*x\n",
    "# m         : Number of data points to be used\n",
    "# n_samples : Number of \"samples\" of approximations to be used for plotting on \"left\" plot\n",
    "# sigma     : Standard deviation for the error added \n",
    "def plot_linear_approximation(a0=1.1,a1=3.5,m=100,n_samples=50, sigma=5e-1):\n",
    "    \n",
    "    a0_min = -3\n",
    "    a0_max = 4\n",
    "    a1_min = 0\n",
    "    a1_max = 8\n",
    "    \n",
    "    # Fixing the 'seed' of the random number generator to obtain reproducible outcomes.\n",
    "    rng = np.random.Generator(np.random.PCG64(seed=0))\n",
    "    \n",
    "    ############################################################\n",
    "    # Generating data and solving the least square problem\n",
    "    ############################################################\n",
    "    # Relationship considered\n",
    "    fv = np.vectorize(lambda x, a0, a1: a0+a1*x)\n",
    "    # \"Exact\" coefficients considered\n",
    "    a0_exact, a1_exact = 1, 4\n",
    "\n",
    "    # Error:\n",
    "    # Standard deviation for the error\n",
    "    # sigma = 5e-1\n",
    "    # Error to be added\n",
    "    e = rng.normal(0, sigma, m)\n",
    "\n",
    "    # Generating data points\n",
    "    x = np.linspace(0,1,m)\n",
    "    y = fv(x,a0_exact,a1_exact)+e\n",
    "    \n",
    "    # Build the data matrix\n",
    "    A = np.ones((m,2))\n",
    "    A[:,1] = x\n",
    "    # Setting up the right hand side\n",
    "    b = y\n",
    "\n",
    "    # Building and solving the normal equations\n",
    "    # A^T A x_bar = A^T b\n",
    "    x_bar = np.linalg.solve(A.T @ A, A.T @ b)\n",
    "    \n",
    "    ############################################################\n",
    "    # Plotting the data\n",
    "    ############################################################\n",
    "    residual = lambda a,b: np.power(np.linalg.norm(y-a*np.ones_like(y)-b*x),2)\n",
    "    residual_v = np.vectorize(residual)\n",
    "    random_perturbations = rng.standard_normal((n_samples,2))\n",
    "\n",
    "    # Showing the comparison between the \"original function\" and the \"least-squared reconstructed approximation\".\n",
    "    # We added in red a \"sample\" of possible functions.\n",
    "    # Notice that the colors used follow the description included in the classnotes.\n",
    "    # This means to consider the following analogy:\n",
    "    # blue: data points, this correspond to the right-hand-side vector \"b\".\n",
    "    # red: this correspond to the sub-space generated by Ax, i.e. the span of the columns of A.\n",
    "    # violet: This correspond to the least-square solution found.\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(121)\n",
    "    # Data points\n",
    "    plt.plot(x,y,'b.',markersize=8, label='Data points',alpha=0.8)\n",
    "    # Non-optimal solutions \n",
    "    for i in range(n_samples-1):\n",
    "        plt.plot(x,fv(x,x_bar[0]+random_perturbations[i,0],x_bar[1]+random_perturbations[i,1]),'-',linewidth=1, alpha=0.2, color='red')\n",
    "    plt.plot(x,fv(x,x_bar[0]+random_perturbations[-1,0],x_bar[1]+random_perturbations[-1,1]),'r-',linewidth=1,alpha=0.2, label='Non-optimal solutions')\n",
    "\n",
    "    # Least-Square approximation\n",
    "    plt.plot(x,fv(x,x_bar[0],x_bar[1]),'-',color='darkviolet',linewidth=4, label=f'Least Square approximation, error: {residual_v(x_bar[0],x_bar[1]):.2f}')\n",
    "    # Input approximation -> provided by widgets\n",
    "    plt.plot(x,fv(x,a0,a1),'-',color='red',linewidth=4, label='Input approximation', alpha=0.5)\n",
    "    # Original functions\n",
    "    plt.plot(x,fv(x,a0_exact,a1_exact),'k-',linewidth=2,alpha=1, label='Original function')\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.ylabel(r'$y$')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([-1,9])\n",
    "    plt.legend(loc='best', ncol=1, fancybox=True, shadow=True, numpoints=1, fontsize=8)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    # This variable define the \"grid\" resolution on each dimension, i.e. the number\n",
    "    # of pixels per dimension.\n",
    "    grid_resolution = 100\n",
    "    a0_range = np.linspace(a0_min, a0_max, grid_resolution)\n",
    "    a1_range = np.linspace(a1_min, a1_max, grid_resolution)\n",
    "    [a_mat,b_mat] = np.meshgrid(a0_range,a1_range)\n",
    "\n",
    "    E = residual_v(a_mat,b_mat)\n",
    "\n",
    "    plt.contourf(a0_range, a1_range, E, levels=20, cmap='Blues')\n",
    "    \n",
    "    # Non-optimal solutions \n",
    "    for i in range(n_samples-1):\n",
    "        plt.plot(x_bar[0]+random_perturbations[i,0],x_bar[1]+random_perturbations[i,1],'r.',linewidth=1, alpha=0.5,markersize=2)\n",
    "    plt.plot(x_bar[0]+random_perturbations[-1,0],x_bar[1]+random_perturbations[-1,1],'r.',linewidth=1,alpha=0.5,markersize=2)\n",
    "   \n",
    "    plt.xlim([a0_min,a0_max])\n",
    "    plt.ylim([a1_min,a1_max])\n",
    "     \n",
    "    plt.xlabel(r'$a_0$')\n",
    "    plt.ylabel(r'$a_1$')\n",
    "    plt.axis('scaled')\n",
    "    plt.plot(a0,a1,'r*',markersize=8)\n",
    "    plt.title(f'Error: {residual_v(a0,a1):.5f}')\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding what happends with the **Least-Square** error\n",
    "\n",
    "The next example shows on the **figure on the left** the following:\n",
    "1. <span style=\"color:blue\">Data points in blue</span>.\n",
    "2. <span style=\"color:red\">Non-optimal (sample) approximations in light-red</span>.\n",
    "3. <span style=\"color:darkmagenta\">The **least-square approximation** in dark magenta</span>.\n",
    "4. <span style=\"color:red\">Input approximation defined by the widget in red with wide line</span>.\n",
    "5. Original function in black.\n",
    "\n",
    "and on the **figure on the right**:\n",
    "1. In the background shows the plot for the least-square error $E(a_0,a_1)=\\sum_{i=1}^m (y_i-a_0-a_1\\,x_i)^2=\\|\\mathbf{y}-a_0\\,\\mathbf{1}-a_1\\,\\mathbf{x}\\|_2$, where $\\mathbf{1}$ is the vector of dimension $m$ of $1$, i.e. $\\mathbf{1}=[1,1,\\dots,1]^\\top$.\n",
    "2. <span style=\"color:red\">Non-optimal (sample) approximations in light-red</span>.\n",
    "3. <span style=\"color:red\">Input approximation defined by the widget in red a red star</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc163b23bec7435d931742c48daae9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.1, description='a0', max=3.0, min=-1.0), FloatSlider(value=3.5, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_linear_approximation(a0=1.1, a1=3.5, m=100, n_samples=50, sigma=0.5)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_linear_approximation,a0=(-1,3,0.1),a1=(2,6,0.1),m=(2,200,1),n_samples=(10,200,10),sigma=(0.0,10.,0.01))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='qr' />\n",
    "\n",
    "# QR Factorization\n",
    "\n",
    "We studied before about the Normal Equations for solving **linear least-square problems**.\n",
    "This is of high theoretical importance, unfortunately, the Normal Equations may show some numerical issues when dealing with large and ill-conditioned matrices.\n",
    "To handle this, we will learn about the QR factorization.\n",
    "The QR factorization will allow us to still find the **least-square** approximation but avoiding computing explicitly the Normal Equations.\n",
    "But before we can connect the QR factorization with the computation of the **least-square** approximation, we need to learn about the computation of the QR factorization of the matrix $A$ used for the **linear least-square problem**.\n",
    "\n",
    "## Gram-Schmidt Orthogonalization\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose for the Gram-Schmidt Orthogonalization is to build an **orthonormal set of vectors** from a **arbitrary** set of vectors such that they **span** the same vector space.\n",
    "For simplicity, we will consider that the **arbitrary** set of vector are **linearly independent** vectors.\n",
    "_If they are not linearly independent vectors, the algorithm will **break-down** at some point. \n",
    "The good news when it **breaks-down** is that it will give us which are linearly independent vectors!_\n",
    "\n",
    "For clarity, we will store in a matrix $A$ the set of **linearly independent** vectors, say $A=[\\mathbf{a}_1\\, ...., \\mathbf{a}_n]$, notice that each vectors $\\mathbf{a}_i\\in\\mathbb{R}^m$ and $n \\le m$.\n",
    "\n",
    "We also know the following for the **orthogonal set** we want to build:\n",
    "$$\\begin{align*}\n",
    "    \\mathbf{q}_i^T\\,\\mathbf{q}_i & = \\|\\mathbf{q}_i\\|_2^2= 1\\\\\n",
    "    \\mathbf{q}_i^T\\,\\mathbf{q}_j & = 0, \\, \\text{ for } i\\neq j\n",
    "\\end{align*}$$\n",
    "\n",
    "Moreover, we have the following relation between the two sets of vectors described:\n",
    "$$\n",
    "\\underbrace{\\begin{bmatrix} \n",
    "\t\\mathbf{a}_{1}, & \\mathbf{a}_{2}, & \\dots, & \\mathbf{a}_{n}\n",
    "\\end{bmatrix}}_{\\displaystyle A}\n",
    "=\n",
    "\\underbrace{\\begin{bmatrix} \n",
    "\t\\mathbf{q}_{1}, & \\mathbf{q}_{2}, & \\dots, & \\mathbf{q}_{n}\n",
    "\\end{bmatrix}}_{\\displaystyle \\widehat{Q}}\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "\tr_{1,1} & r_{1,2} & r_{1,3} & \\dots  &  r_{1,n} \\\\\n",
    "\t0      & r_{2,2} & r_{2,3} & \\dots  &  r_{2,n} \\\\\n",
    "\t0      & 0      & r_{3,3} & \\dots  &  r_{3,n} \\\\\n",
    "\t\\vdots & \\vdots & \\ddots & \\ddots &  \\vdots \\\\\n",
    "\t0      & \\dots  & \\dots  &  0     &  r_{nn}\n",
    "\\end{bmatrix}}_{\\displaystyle \\widehat{R}}.$$\n",
    "This identity, by means of comparing each column on the **left hand side** with its corresponding column on the **right hand side**, give us:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\mathbf{a}_{1} &= r_{1,1}\\,\\mathbf{q}_{1},\\\\\n",
    "    \\mathbf{a}_{2} &= r_{1,2}\\,\\mathbf{q}_{1}+r_{2,2}\\,\\mathbf{q}_{2},\\\\\n",
    "    \\mathbf{a}_{3} &= r_{1,3}\\,\\mathbf{q}_{1}+r_{2,3}\\,\\mathbf{q}_{2}+r_{3,3}\\,\\mathbf{q}_{3},\\\\\n",
    "    \\vdots          &\\qquad \\vdots\\\\\n",
    "    \\mathbf{a}_k   &= r_{1,k}\\,\\mathbf{q}_{1}+r_{2,k}\\,\\mathbf{q}_{2}+\\dots+r_{k,k}\\,\\mathbf{q}_{k} &= \\displaystyle\\sum_{i=1}^{k} r_{i,k}\\,\\mathbf{q}_{i},\\\\\n",
    "    \\vdots          &\\qquad \\vdots\\\\\n",
    "    \\mathbf{a}_{n} &= r_{1,n}\\,\\mathbf{q}_{1} + r_{2,n}\\,\\mathbf{q}_{2}+\\dots+r_{n,n}\\,\\mathbf{q}_{n} &= \\displaystyle\\sum_{i=1}^{n} r_{i,n}\\,\\mathbf{q}_{i}.\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then the **classic** Gram-Schmidt orthonormalization finds $\\mathbf{q}_i$ and $r_{i,j}$ as follows.\n",
    "\n",
    "- First equation: $\\mathbf{a}_1 = r_{1,1}\\,\\mathbf{q}_1$, we obtain,\n",
    "    - $r_{1,1} = \\|\\mathbf{a}_1\\|_2$\n",
    "    - $\\mathbf{q}_1 = \\dfrac{\\mathbf{a}_1}{r_{11}}$\n",
    "- Second equation: $\\mathbf{a}_2 = r_{1,2}\\,\\mathbf{q}_1+r_{2,2}\\,\\mathbf{q}_2$, we obtain,\n",
    "    - $r_{1,2} = \\mathbf{q}_1^\\top\\,\\mathbf{a}_2$\n",
    "    - $r_{2,2} = \\|\\mathbf{a}_2-r_{1,2}\\,\\mathbf{q}_1\\|_2$\n",
    "    - $\\mathbf{q}_2 = \\dfrac{\\mathbf{a}_2-r_{1,2}\\,\\mathbf{q}_1}{r_{2,2}}$\n",
    "- **Third equation** (we highlight this equation to explain below the **modified** Gram-Schmidt orthonormalization): $\\mathbf{a}_3 = r_{1,3}\\,\\mathbf{q}_{1}+r_{2,3}\\,\\mathbf{q}_{2}+r_{3,3}\\,\\mathbf{q}_{3}$, we obtain,\n",
    "    - $r_{1,3} = \\mathbf{q}_1^\\top\\,\\mathbf{a}_3$\n",
    "    - $r_{2,3} = \\mathbf{q}_2^\\top\\,\\mathbf{a}_3$\n",
    "    - $r_{3,3} = \\|\\mathbf{a}_3-r_{1,3}\\,\\mathbf{q}_1-r_{2,3}\\,\\mathbf{q}_2\\|_2$\n",
    "    - $\\mathbf{q}_3 = \\dfrac{\\mathbf{a}_3-r_{1,3}\\,\\mathbf{q}_1-r_{2,3}\\,\\mathbf{q}_2}{r_{3,3}}$\n",
    "- Now, following the same idea, we move to the $k$-th equation, $\\mathbf{a}_k = \\sum_{i=1}^k r_{i,k}\\,\\mathbf{q}_i$, for which we obtain,\n",
    "    - $r_{i,k} = \\mathbf{q}_i^\\top\\,\\mathbf{a}_k, \\, \\textrm{ for } i<k$\n",
    "    - $r_{k,k} = \\left\\|\\mathbf{a}_k-\\sum_{i=1}^{k-1} r_{i,k}\\,\\mathbf{q}_i\\right\\|_2\\\\$\n",
    "    - $\\mathbf{q}_k = \\dfrac{\\mathbf{a}_k-\\sum_{i=1}^{k-1} r_{i,k}\\,\\mathbf{q}_i}{r_{k,k}}$\n",
    "- And, for the $n$-th (final) term, $\\mathbf{a}_n = \\sum_{i=1}^n r_{i,n}\\,\\mathbf{q}_i$, we obtain,\n",
    "    - $r_{i,n} = \\mathbf{q}_i^T\\,\\mathbf{a}_n, \\, \\textrm{ for } i<n$\n",
    "    - $r_{n,n} = \\left\\|\\mathbf{a}_n-\\sum_{i=1}^{n-1} r_{in}\\,\\mathbf{q}_i\\right\\|_2$\n",
    "    - $\\mathbf{q}_n = \\dfrac{\\mathbf{a}_n-\\sum_{i=1}^{n-1} r_{i,n}\\,\\mathbf{q}_i}{r_{n,n}}$\n",
    "\n",
    "Thus, we obtain the reduced QR factorization as follows:\n",
    "$$\n",
    "\\begin{equation}\n",
    "                 \\mathbf{A}_{m\\times n} = \\widehat{Q}_{m\\times n}\\widehat{R}_{n\\times n},\n",
    "\\end{equation}$$\n",
    "where $\\widehat{Q}$ is a matrix of vectors $\\mathbf{q}_{k}$, and $\\widehat{R}$ is an upper-triangular matrix, with the coefficients $r_{i,k}$:\n",
    "\n",
    "### **[IMPORTANT]** \n",
    "- What is then a **full** QR factorization?\n",
    "    - The **full QR** factorization is the following $A=Q\\,R$, where $Q$ is an $m\\times m$ matrix and $R$ is an $m\\times n$ matrix. \n",
    "    The first $n$ columns of $Q$ are the columns of $\\widehat{Q}$ and the other $m-n$ columns are the complement vectors such that the range of $Q$ is $\\mathcal{R}^m$.\n",
    "    On the other hand, the matrix $R$ is compose by the matrix $\\widehat{R}$ on the first $n$ rows and then a matrix of zeros of size $(m-n)\\times n$.\n",
    "    This ensures that $A=Q\\,R=\\widehat{Q}\\,\\widehat{R}$.\n",
    "- What is then a **modified** Gram-Schmidt orthonormalization?\n",
    "    To explain better the effect of the **modified** Gram-Schmidt orthonormalization, we point out the \"**Third equation**\".\n",
    "    Notice that the equation is the same, <span style=\"color:blue\">__**but the difference relies on how we compute the $r_{i,k}$ coefficients**__</span>, thus,\n",
    "    - Third equation: $\\mathbf{a}_3 = r_{1,3}\\,\\mathbf{q}_{1}+r_{2,3}\\,\\mathbf{q}_{2}+r_{3,3}\\,\\mathbf{q}_{3}$, we obtain,\n",
    "        - $r_{1,3} = \\mathbf{q}_1^\\top\\,\\mathbf{a}_3$ $\\color{blue}\\leftarrow\\color{blue}$ <span style=\"color:blue\"> Same procedure as before</span>\n",
    "        - $r_{2,3} = \\mathbf{q}_2^\\top\\,\\left(\\mathbf{a}_3-r_{1,3}\\,\\mathbf{q}_{1}\\right)$ $\\color{red}\\leftarrow\\color{red}$ <span style=\"color:red\"> **Modified** procedure. This is Mathematically equivalent but numerically much better</span>\n",
    "        - $r_{3,3} = \\|\\mathbf{a}_3-r_{1,3}\\,\\mathbf{q}_1-r_{2,3}\\,\\mathbf{q}_2\\|_2$ $\\color{blue}\\leftarrow\\color{blue}$ <span style=\"color:blue\"> Same procedure as before</span>\n",
    "        - $\\mathbf{q}_3 = \\dfrac{\\mathbf{a}_3-r_{1,3}\\,\\mathbf{q}_1-r_{2,3}\\,\\mathbf{q}_2}{r_{3,3}}$ $\\color{blue}\\leftarrow\\color{blue}$ <span style=\"color:blue\"> Same procedure as before</span>\n",
    "    - For the general $k$-th step we get, $\\mathbf{a}_k = \\sum_{i=1}^k r_{i,k}\\,\\mathbf{q}_i$, for which we obtain,\n",
    "        - $r_{1,k} = \\mathbf{q}_1^\\top\\,\\mathbf{a}_k$ $\\color{blue}\\leftarrow\\color{blue}$ <span style=\"color:blue\"> Same procedure as before</span> \n",
    "        - $r_{i,k} = \\mathbf{q}_i^\\top\\,\\left(\\mathbf{a}_k - \\sum_{j=1}^{i-1} r_{j,k}\\,\\mathbf{q}_j\\right), \\, \\textrm{ for } 2\\leq i<k$, $\\color{red}\\leftarrow\\color{red}$ <span style=\"color:red\"> **Modified** procedure</span>\n",
    "        - $r_{k,k} = \\left\\|\\mathbf{a}_k-\\sum_{i=1}^{k-1} r_{i,k}\\,\\mathbf{q}_i\\right\\|_2\\,$ $\\color{blue}\\leftarrow\\color{blue}$ <span style=\"color:blue\"> Same procedure as before</span>\n",
    "        - $\\mathbf{q}_k = \\dfrac{\\mathbf{a}_k-\\sum_{i=1}^{k-1} r_{i,k}\\,\\mathbf{q}_i}{r_{k,k}}$ $\\color{blue}\\leftarrow\\color{blue}$ <span style=\"color:blue\"> Same procedure as before</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements the 'classic' and 'modified' Gram-Schmidt procedures for the 'reduced' factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR(A, type_factorization = 'reduced', type_gram_schmidt='classic'):\n",
    "    A.astype('float')\n",
    "    m,n = A.shape # m: number of rows, n: number of columns.\n",
    "    if type_factorization == 'reduced':\n",
    "        Q = np.zeros((m,n))\n",
    "        R = np.zeros((n,n))\n",
    "    elif type_factorization == 'full':\n",
    "        Q = np.zeros((m,m))\n",
    "        R = np.zeros((m,n))\n",
    "    for k in range(n):\n",
    "        y = A[:,k]\n",
    "        for i in range(k):\n",
    "            if type_gram_schmidt == 'classic':\n",
    "                R[i,k] = np.dot(Q[:,i],A[:,k])\n",
    "            elif type_gram_schmidt == 'modified':\n",
    "                R[i,k] = np.dot(Q[:,i],y)\n",
    "            y=y-R[i,k]*Q[:,i]\n",
    "        R[k,k] = np.linalg.norm(y)\n",
    "        Q[:,k] = y/R[k,k]\n",
    "    # The following lines must be completed by you!\n",
    "    #if type_factorization == 'full': \n",
    "        # (1) We need to add 0's to the R matrix so it is of the same shape as the matrix A, \n",
    "        # fortunately this was already done!\n",
    "        # (2) We need to add orthogonal vectors to Q so it is square,\n",
    "        # how do we do this?\n",
    "    return Q,R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### First example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[43mA:\n",
      "\u001b[0m [[ 1 -4]\n",
      " [ 2  3]\n",
      " [ 2  2]]\n",
      "\u001b[1m\u001b[43mQ_hat @ R_hat:\n",
      "\u001b[0m [[ 1. -4.]\n",
      " [ 2.  3.]\n",
      " [ 2.  2.]]\n",
      "\u001b[1m\u001b[43mQ_hat:\n",
      "\u001b[0m [[ 0.33333333 -0.93333333]\n",
      " [ 0.66666667  0.33333333]\n",
      " [ 0.66666667  0.13333333]]\n",
      "\u001b[1m\u001b[43mR_hat:\n",
      "\u001b[0m [[3. 2.]\n",
      " [0. 5.]]\n",
      "\u001b[1m\u001b[43mQ_hat.T @ Q_hat:\n",
      "\u001b[0m [[1.00000000e+00 2.28212511e-17]\n",
      " [2.28212511e-17 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,-4],[2,3],[2,2]])\n",
    "Q_hat, R_hat = QR(A, type_factorization ='reduced', type_gram_schmidt='classic')\n",
    "print(textBoldH('A:\\n'),A)\n",
    "print(textBoldH('Q_hat @ R_hat:\\n'), Q_hat @ R_hat)\n",
    "print(textBoldH('Q_hat:\\n'), Q_hat)\n",
    "print(textBoldH('R_hat:\\n'), R_hat)\n",
    "print(textBoldH('Q_hat.T @ Q_hat:\\n'), Q_hat.T @ Q_hat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='DoWeReallyHaveUnitaryVectors' />\n",
    "\n",
    "## Do we really have _truly_ unitary vectors?\n",
    "\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "This is an example that shows that unitary vectors are not truly unitary in _double precision_!\n",
    "For instance, in this case we define the vector $\\mathbf{v}=[1,\\delta]$, and we then make it unitary, which should result in $\\mathbf{w}=\\dfrac{\\mathbf{v}}{\\|\\mathbf{v}\\|}=\\left[\\dfrac{1}{\\sqrt{1+\\delta^2}},\\dfrac{\\delta}{\\sqrt{1+\\delta^2}}\\right]$.\n",
    "This is indeed true for _not too small_ values of $\\delta$, however if $\\delta^2<\\epsilon_{\\text{mach}}$, then the resulting vector $\\mathbf{w}$ will be equal to $\\mathbf{v}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa021eb659146229202f45c621dd263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=20, min=-20), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_unitary_vector(n=0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_unitary_vector(n=0):\n",
    "    # Small value 'delta'.\n",
    "    delta = np.power(10.,n)\n",
    "    \n",
    "    print(textBold(f'delta=10^n= \\t\\t:'),delta)\n",
    "    \n",
    "    v=np.array([1,delta])\n",
    "    print(textBold(f'Vector v\\t\\t:'),v)\n",
    "\n",
    "    w=v/np.linalg.norm(v)\n",
    "    \n",
    "    print(textBold(f'Vector w=v/||v||\\t:'),w)\n",
    "    \n",
    "    print(textBold(f'Vector v-w=\\t\\t:'),v-w)\n",
    "\n",
    "    #print('Thus, they are the same for small values of d!!\\nThis means that w is not truly unitary!')\n",
    "    print(textBoldH(r'Are they different for all values of $\\delta=10^{n}$?'))\n",
    "\n",
    "interact(show_unitary_vector,n=(-20,20,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='ex' />\n",
    "\n",
    "## Examples of QR: Classic vs Modified Gram-Schmidt\n",
    "\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mA: \n",
      "\u001b[0m [[1.e+00 1.e+00 1.e+00]\n",
      " [1.e-10 0.e+00 0.e+00]\n",
      " [0.e+00 1.e-10 0.e+00]\n",
      " [0.e+00 0.e+00 1.e-10]]\n",
      "\u001b[1m\u001b[43m\n",
      " What are the Q's?\u001b[0m\n",
      "\u001b[1m\u001b[31mQc: \n",
      "\u001b[0m [[ 1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e-10 -7.07106781e-01 -7.07106781e-01]\n",
      " [ 0.00000000e+00  7.07106781e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  7.07106781e-01]]\n",
      "\u001b[1m\u001b[34mQm: \n",
      "\u001b[0m [[ 1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e-10 -7.07106781e-01 -4.08248290e-01]\n",
      " [ 0.00000000e+00  7.07106781e-01 -4.08248290e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  8.16496581e-01]]\n",
      "\u001b[1m\u001b[43m\n",
      " Are truly orthogonal the q_i's?\u001b[0m\n",
      "\u001b[1m\u001b[31mQc.T*Qc: \n",
      "\u001b[0m [[ 1.00000000e+00 -7.07106781e-11 -7.07106781e-11]\n",
      " [-7.07106781e-11  1.00000000e+00  5.00000000e-01]\n",
      " [-7.07106781e-11  5.00000000e-01  1.00000000e+00]]\n",
      "\u001b[1m\u001b[31m||Qc.T*Qc-I_3||: \u001b[0m 0.7071067811865477\n",
      "\u001b[1m\u001b[43m\u001b[37mNot really, since q2^T*q3 \\neq 0.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " Qm.T*Qm: \n",
      "\u001b[0m [[ 1.00000000e+00 -7.07106781e-11 -4.08248290e-11]\n",
      " [-7.07106781e-11  1.00000000e+00 -1.54826171e-16]\n",
      " [-4.08248290e-11 -1.54826171e-16  1.00000000e+00]]\n",
      "1.1547005383855975e-10\n",
      "\u001b[1m\u001b[34m||Qm.T*Qm-I_3||: \u001b[0m 1.1547005383855975e-10\n",
      "\u001b[1m\u001b[43m\u001b[37mThis looks much better!\u001b[0m\n",
      "\u001b[1m\u001b[43m\n",
      " Do we recover A with each algorithm?\u001b[0m\n",
      "\u001b[1m\u001b[31mA-Qc*Rc: \n",
      "\u001b[0m [[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.62324963e-27 3.62324963e-27]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\u001b[1m\u001b[31m||A-Qc*Rc||: \u001b[0m 5.124048771544536e-27\n",
      "\u001b[1m\u001b[43m\u001b[37mYes!\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      " A-Qm*Rm: \n",
      "\u001b[0m [[0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 3.62324963e-27 1.77879510e-27]\n",
      " [0.00000000e+00 0.00000000e+00 3.12420006e-27]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\u001b[1m\u001b[34m||A-Qm*Rm||: \u001b[0m 5.104182200807197e-27\n",
      "\u001b[1m\u001b[43m\u001b[37mYes!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Example 4.16 from textbook.\n",
    "d = 1e-10\n",
    "A = np.array([[1,1,1],[d,0,0],[0,d,0],[0,0,d]])\n",
    "print(textBold('A: \\n'), A)\n",
    "\n",
    "Qc,Rc = QR(A, type_gram_schmidt = 'classic')\n",
    "Qm,Rm = QR(A, type_gram_schmidt = 'modified')\n",
    "\n",
    "################################\n",
    "print(textBoldH('\\n What are the Q\\'s?'))\n",
    "print(textQRClassic('Qc: \\n'), Qc)\n",
    "print(textQRModified('Qm: \\n'), Qm)\n",
    "\n",
    "################################\n",
    "print(textBoldH('\\n Are truly orthogonal the q_i\\'s?'))\n",
    "print(textQRClassic('Qc.T*Qc: \\n'),np.dot(Qc.T,Qc))\n",
    "print(textQRClassic('||Qc.T*Qc-I_3||: '),np.linalg.norm(np.dot(Qc.T,Qc)-np.eye(3))) # Warning: We are just using the transpose since the matrices are real!\n",
    "print(textAnswer('Not really, since q2^T*q3 \\\\neq 0.'))\n",
    "\n",
    "print(textQRModified('\\n Qm.T*Qm: \\n'),np.dot(Qm.T,Qm))\n",
    "print(np.linalg.norm(np.dot(Qm.T,Qm)-np.eye(3)))\n",
    "print(textQRModified('||Qm.T*Qm-I_3||: '),np.linalg.norm(np.dot(Qm.T,Qm)-np.eye(3)))\n",
    "print(textAnswer('This looks much better!'))\n",
    "\n",
    "################################\n",
    "print(textBoldH('\\n Do we recover A with each algorithm?'))\n",
    "print(textQRClassic('A-Qc*Rc: \\n'),A-np.dot(Qc,Rc))\n",
    "print(textQRClassic('||A-Qc*Rc||: '),np.linalg.norm(A-np.dot(Qc,Rc)))\n",
    "print(textAnswer('Yes!'))\n",
    "\n",
    "print(textQRModified('\\n A-Qm*Rm: \\n'),A-np.dot(Qm,Rm))\n",
    "print(textQRModified('||A-Qm*Rm||: '),np.linalg.norm(A-np.dot(Qm,Rm)))\n",
    "print(textAnswer('Yes!'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='qrls' />\n",
    "\n",
    "## Using the QR factorization to solve least-square problems\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "We really encourage to take a look to the classnotes to understand the theory behind the use of the QR factorization.\n",
    "Here, we will focus on the direct application of it for linear least-square problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the linear least-square problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points to be used\n",
    "m = 100\n",
    "# Relationship considered\n",
    "fv = np.vectorize(lambda x, a0, a1: a0+a1*x)\n",
    "# \"Exact\" coefficients considered\n",
    "a0_exact, a1_exact = 1, 4\n",
    "\n",
    "# Fixing the 'seed' of the random number generator to obtain reproducible outcomes.\n",
    "rng = np.random.Generator(np.random.PCG64(seed=0))\n",
    "\n",
    "# Error:\n",
    "# Standard deviation for the error\n",
    "sigma = 5e-1\n",
    "# Error to be added\n",
    "e = rng.normal(0, sigma, m)\n",
    "\n",
    "# Generating data points\n",
    "x = np.linspace(0,1,m)\n",
    "y = fv(x,a0_exact,a1_exact)+e\n",
    "\n",
    "# Build the data matrix\n",
    "A = np.ones((m,2))\n",
    "A[:,1] = x\n",
    "# Setting up the right hand side\n",
    "b = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the least-square problem with the Normal Equations\n",
    "\n",
    "This is what we already did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00415184 4.07279301]\n"
     ]
    }
   ],
   "source": [
    "# Building and solving the normal equations\n",
    "# A^T A x_bar = A^T b\n",
    "x_bar = np.linalg.solve(A.T @ A, A.T @ b)\n",
    "print(x_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the least-square problem with the **Reduced QR factorization**\n",
    "1. Using our implementation\n",
    "2. Using the Numpy's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00415184 4.07279301]\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "Q,R = QR(A, type_factorization = 'reduced', type_gram_schmidt='modified')\n",
    "x_bar_our = spla.solve_triangular(R,np.dot(Q.T,b))\n",
    "print(x_bar_our)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00415184 4.07279301]\n"
     ]
    }
   ],
   "source": [
    "# 2.\n",
    "Qnp, Rnp = np.linalg.qr(A)\n",
    "x_bar_numpy = spla.solve_triangular(Rnp,np.dot(Qnp.T,b))\n",
    "print(x_bar_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a conclusion, we get the same result in all cases!\n",
    "\n",
    "**Therefore, we strongly suggest you to use the QR factorization for solving linear least-square problems**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='sm' />\n",
    "\n",
    "# Additional examples\n",
    "[Back to TOC](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(A,b):\n",
    "    Q,R = QR(A,type_gram_schmidt='modified')\n",
    "    return spla.solve_triangular(R,np.dot(Q.T,b))\n",
    "\n",
    "def solve_model(M):\n",
    "    A=M['A']\n",
    "    b=M['b']\n",
    "    M['x_bar']=least_squares(A,b)\n",
    "    return M\n",
    "\n",
    "def create_model(data, type_model='linear'):\n",
    "    if type_model == 'linear': # f(x)=a0+a1*x\n",
    "        A = np.ones((data.shape[0],2))\n",
    "        A[:,1] = data[:,0]\n",
    "        b = data[:,1]\n",
    "    if type_model == 'parabollic': # f(x)=a0+a1*x+a_2*x^2\n",
    "        A = np.ones((data.shape[0],3))\n",
    "        A[:,1] = data[:,0]\n",
    "        A[:,2] = data[:,0]**2\n",
    "        b = data[:,1]\n",
    "    if type_model == 'exponential': #f(x)=a0 \\exp(a1*x) = \\exp(\\log(a0)+a1*x) -> log(f(x))=log(a0)+a1*x = A0+a1+x (it is linear now!)\n",
    "        A = np.ones((data.shape[0],2))\n",
    "        A[:,1] = data[:,0]\n",
    "        b = np.log(data[:,1])\n",
    "    M = {'A':A,\n",
    "         'b':b,\n",
    "         'type_model':type_model}\n",
    "    M=solve_model(M)\n",
    "    return M\n",
    "\n",
    "def evaluate_model(M,x):\n",
    "    x_bar=M['x_bar']\n",
    "    if M['type_model'] == 'linear':\n",
    "        return x_bar[0] + x_bar[1]*x\n",
    "    if M['type_model'] == 'parabollic':\n",
    "        return x_bar[0] + x_bar[1]*x + x_bar[2]*x**2\n",
    "    if M['type_model'] == 'exponential':\n",
    "        return np.exp(x_bar[0]+x_bar[1]*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(type_of_data='linear'):\n",
    "    n=40\n",
    "    np.random.seed(0)\n",
    "    x = np.linspace(0,10,n)\n",
    "    y = np.random.rand(n)\n",
    "    x = np.concatenate((x,x,y),axis=0)\n",
    "    n = 3*n\n",
    "    if type_of_data=='linear':\n",
    "        y = x+0.1*np.random.normal(0,1,n)+1.5\n",
    "    elif type_of_data=='parabollic':\n",
    "        y = 4*x**2+0.1*x*np.random.normal(0,1,n)+1.5\n",
    "    elif type_of_data=='exponential':\n",
    "        y = np.exp(x+0.1*np.random.normal(0,1,n)+1.5)\n",
    "    elif type_of_data=='sinusoidal':\n",
    "        y = np.sin(2*np.pi*x/10)+0.1*np.random.normal(0,1,n)+1.5\n",
    "    elif type_of_data=='random':\n",
    "        y = 0.1*np.random.normal(0,1,n)+1.5\n",
    "    elif type_of_data=='diabetes':\n",
    "        x,y=datasets.load_diabetes(return_X_y=True)\n",
    "        x=x[:,2]\n",
    "    data = np.stack((x, y)).T\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4889a58d05b940a296f3518306b4164f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='type_of_data', index=5, options=('linear', 'parabollic', 'exponent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.looking_at_data(type_of_data='diabetes')>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def looking_at_data(type_of_data='diabetes'):\n",
    "    data=generate_data(type_of_data)\n",
    "    Ml = create_model(data, type_model='linear')\n",
    "    Mp = create_model(data, type_model='parabollic')\n",
    "    Me = create_model(data, type_model='exponential')\n",
    "    xx=np.linspace(np.min(data[:,0])-0.1,np.max(data[:,0])+0.1,1000)\n",
    "    yyl=evaluate_model(Ml,xx)\n",
    "    yyp=evaluate_model(Mp,xx)\n",
    "    yye=evaluate_model(Me,xx)\n",
    "    \n",
    "    error_l=data[:,1]-evaluate_model(Ml,data[:,0])\n",
    "    error_p=data[:,1]-evaluate_model(Mp,data[:,0])\n",
    "    error_e=data[:,1]-evaluate_model(Me,data[:,0])\n",
    "    \n",
    "    plt.figure(figsize=(2*M,M))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(xx,yyl,'k-',linewidth=5,label='linear model')\n",
    "    plt.plot(xx,yyp,'y-',linewidth=20,label='parabollic model',alpha=0.4)\n",
    "    plt.plot(xx,yye,'g-',linewidth=5,label='exponential model')\n",
    "    plt.plot(data[:,0],data[:,1],'.b',markersize=20,label='original data',alpha=0.3)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.ylabel(r'$y$')\n",
    "    plt.legend(loc='best')\n",
    "    #plt.ylim(0,10)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.title('What does this histogram tell us?')\n",
    "    three_errors=np.vstack((error_l, error_p, error_e)).T\n",
    "    plt.hist(three_errors, bins=20,\n",
    "             label=['linear','parabollic','exponential'],\n",
    "             color=['k','y','g'], alpha=0.5)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "widgets.interact(looking_at_data,type_of_data=['linear','parabollic','exponential','sinusoidal','random','diabetes'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[Back to TOC](#toc)\n",
    "\n",
    "### Numpy Least Squares\n",
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html\n",
    "\n",
    "### Numpy QR Factorization\n",
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.qr.html\n",
    "\n",
    "### Scikit Learn Datasets\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n",
    "\n",
    "### Colorama\n",
    "https://pypi.org/project/colorama/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='acknowledgements' />\n",
    "\n",
    "# Acknowledgements\n",
    "[Back to TOC](#toc)\n",
    "* _Material created by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) _and assistans: Laura Bermeo, Alvaro Salinas, Axel Símonsen and Martín Villanueva. DI UTFSM. April 2016._\n",
    "* _Material updated by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) DI UTFSM. June 2017.\n",
    "* _Material updated by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) DI UTFSM. July 2019.\n",
    "* _Material updated by professor Claudio Torres_ (`ctorres@inf.utfsm.cl`) DI UTFSM. August 2019.\n",
    "* _Update July 2020 - v1.27 - C.Torres_ : Fixing formatting issues.\n",
    "* _Update June 2021 - v1.28 - C.Torres_ : Re-ordering notebook and adding TOC link.\n",
    "* _Update June 2021 - v1.29 - C.Torres_ : Adding \"initial example\" in the section \"Overdetermined Linear Systems of Equations\".\n",
    "* _Update June 2021 - v1.30 - C.Torres_ : Adding colors to the numerical example of QR factorization.\n",
    "* _Update June 2021 - v1.31 - C.Torres_ : Adding more colors and an example to show that unitary vectors in double precision may not be truly unitary! And answers in the QR example.\n",
    "* _Update June 2021 - v1.32 - C.Torres_ : Update of QR implementation, using 'm' and 'n', and including sub-index 'k' to match the 'LaTex' explanation and classnotes.\n",
    "* _Update November 2021 - v1.33 - C.Torres_ : Updating text, adding a widget for unitary vectors.\n",
    "* _Update November 2021 - v1.34 - C.Torres_ : Updating TOC.\n",
    "* _Update May 2022 - v1.35 - C.Torres_ : Adding legend to the plots.\n",
    "* _Update October 2023 - v1.36 - C.Torres_ : Removing `np.linalg.norm` that was not needed in the implementation of the QR factorization.\n",
    "* _Update May 2024 - v1.37 - C.Torres_ : Updating the use of strings for Python 3.12.*.\n",
    "* _Update May 2024 - v1.38 - C.Torres_ : Large re-organization, major update and adding new plots.\n",
    "* _Update March 2025 - v1.39 - C.Torres_ : Moved to new github repo, updating subplots and fixing some latex issues.\n",
    "* _Update March 2025 - v1.40 - C.Torres_ : Adding Colab link.\n",
    "* _Update September 2025 - v1.41 - C.Torres_ : Updating title section and adding CoLab requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "state": {
    "7fd91d6f0d2545e7af10aae93cfe07e9": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
